{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.7058,  1.9212,  0.0000,  2.4407]),\n",
       " array([-1.70580685,  1.92115259,  0.        ,  2.44069219]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import linear_model\n",
    "# torch.manual_seed(42)\n",
    "# x = torch.Tensor([1,0,3,0,8,0,0,0,0,0])\n",
    "# # x = torch.Tensor([0,3,1,2])\n",
    "# A = torch.randn(3,10)\n",
    "# A = A/torch.norm(A, dim=0, keepdim=True)\n",
    "# y = A @ x\n",
    "x2 = torch.Tensor([0,3,2,1])\n",
    "x = x2\n",
    "# X = torch.Tensor([[0,3],[3,2],[1,0],[2,1]])\n",
    "A = torch.Tensor([[-0.8,0.3,1,0.4],[-0.2,0.4,-0.3,-0.4],[0.2,1,-0.1,0.8]])\n",
    "A = A/torch.norm(A, dim=0, keepdim=True)\n",
    "y = A @ x\n",
    "\n",
    "# y = Dx\n",
    "def orthogonal_matching_pursuit(compressed_vector, compression_matrix, sparsity,err_treshold=1e-6):\n",
    "    # initialize\n",
    "    # compression_matrix_norm = torch.norm(compression_matrix, dim=0, keepdim=True)\n",
    "    unit_compression_matrix = compression_matrix \n",
    "    subsapce_index_list = []\n",
    "    residual = compressed_vector\n",
    "    k = 1\n",
    "    sparsity_vecotr = torch.zeros(compression_matrix.shape[1])\n",
    "    err = torch.sum(residual**2)\n",
    "    while k <= sparsity and err > err_treshold:\n",
    "        residual_projection_matrix = torch.abs(unit_compression_matrix.T @ residual)\n",
    "        _, matching_basis_index = torch.max(residual_projection_matrix, dim=0)\n",
    "        subsapce_index_list.append(matching_basis_index.item())\n",
    "        subspace_matrix = compression_matrix[:, subsapce_index_list]\n",
    "        subspace_matrix_pinv = torch.pinverse(subspace_matrix)\n",
    "        subspace_coordinates = subspace_matrix_pinv @ compressed_vector\n",
    "        subspace_representation = subspace_matrix @ subspace_coordinates\n",
    "        residual = compressed_vector - subspace_representation\n",
    "        err = torch.sum(residual**2)\n",
    "        k += 1\n",
    "    sparsity_vecotr[subsapce_index_list] = subspace_coordinates\n",
    "    return sparsity_vecotr\n",
    "\n",
    "orthogonal_matching_pursuit(y,A, sparsity=4,err_treshold=1e-6), linear_model.orthogonal_mp(A.numpy(),y.numpy(), n_nonzero_coefs=4, tol=1e-6)\n",
    "# len(torch.nonzero(torch.zeros(7,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8529, -1.7058],\n",
       "         [ 2.4606,  1.9212],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 2.7203,  2.4407]]),\n",
       " array([[-0.85290349, -1.70580673],\n",
       "        [ 2.46057558,  1.92115247],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 2.72034669,  2.44069266]]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x1 = torch.Tensor([0,3,1,2])\n",
    "x2 = torch.Tensor([0,3,2,1])\n",
    "\n",
    "X = torch.stack([x1,x2], dim=1)\n",
    "# X = torch.Tensor([[0,3],[3,2],[1,0],[2,1]])\n",
    "A = torch.Tensor([[-0.8,0.3,1,0.4],[-0.2,0.4,-0.3,-0.4],[0.2,1,-0.1,0.8]])\n",
    "A = A/torch.norm(A, dim=0, keepdim=True)\n",
    "Y = A @ X\n",
    "\n",
    "_, origin_dim = A.shape\n",
    "_, sample_num = Y.shape\n",
    "sparisty_matrix = torch.zeros(origin_dim, sample_num)\n",
    "\n",
    "for sample_index in range(sample_num):\n",
    "    y = Y[:,sample_index]\n",
    "    sparisty_matrix[:,sample_index] = orthogonal_matching_pursuit(y, A, sparsity=4, err_treshold=1e-6)\n",
    "sparisty_matrix, linear_model.orthogonal_mp(A.numpy(),Y.numpy(), n_nonzero_coefs=4, tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import linear_model\n",
    "\n",
    "def orthogonal_matching_pursuit(\n",
    "    compressed_vector, compression_matrix, sparsity, err_treshold=None\n",
    "):\n",
    "    '''\n",
    "    Args:\n",
    "        compressed_vector: (compression_dim, )\n",
    "        compression_matrix: (compression_dim, sample_dim)\n",
    "    Returns:\n",
    "        sparsity_vecotr: (sample_dim, )\n",
    "    '''\n",
    "    # initialize\n",
    "    # compression_matrix_norm = torch.norm(compression_matrix, dim=0, keepdim=True)\n",
    "    unit_compression_matrix = compression_matrix\n",
    "    subsapce_index_list = []\n",
    "    residual = compressed_vector\n",
    "    k = 1\n",
    "    sparsity_vecotr = torch.zeros(\n",
    "        compression_matrix.shape[1], device=compressed_vector.device\n",
    "    )\n",
    "    while k <= sparsity:\n",
    "        residual_projection_matrix = torch.abs(unit_compression_matrix.T @ residual)\n",
    "        _, matching_basis_index = torch.max(residual_projection_matrix, dim=0)\n",
    "        subsapce_index_list.append(matching_basis_index.item())\n",
    "        subspace_matrix = compression_matrix[:, subsapce_index_list]\n",
    "        subspace_matrix_pinv = torch.pinverse(subspace_matrix)\n",
    "        subspace_coordinates = subspace_matrix_pinv @ compressed_vector\n",
    "        subspace_representation = subspace_matrix @ subspace_coordinates\n",
    "        residual = compressed_vector - subspace_representation\n",
    "        err = torch.sum(residual**2)\n",
    "        if err_treshold is not None and err <= err_treshold:\n",
    "            break\n",
    "        k += 1\n",
    "    sparsity_vecotr[subsapce_index_list] = subspace_coordinates\n",
    "    return sparsity_vecotr\n",
    "\n",
    "\n",
    "def orthogonal_matching_pursuit_matrix(\n",
    "    compressed_matrix, compression_matrix, sparsity, err_treshold=None\n",
    "):\n",
    "    '''\n",
    "    Args:\n",
    "        compressed_matrix: (compression_dim, sample_num)\n",
    "        compression_matrix: (compression_dim, sample_dim)\n",
    "    Returns:\n",
    "        sparsity_matrix: (sample_dim, sample_num)\n",
    "    '''\n",
    "    _, sample_num = compressed_matrix.shape\n",
    "    _, sample_dim = compression_matrix.shape\n",
    "    sparsity_matrix = torch.zeros(\n",
    "        sample_dim, sample_num, device=compressed_matrix.device\n",
    "    )\n",
    "    for sample_idx in range(sample_num):\n",
    "        compressed_vector = compressed_matrix[:, sample_idx]\n",
    "        sparsity_vecotr = orthogonal_matching_pursuit(\n",
    "            compressed_vector,\n",
    "            compression_matrix,\n",
    "            sparsity=sparsity,\n",
    "            err_treshold=err_treshold,\n",
    "        )\n",
    "        sparsity_matrix[:, sample_idx] = sparsity_vecotr\n",
    "\n",
    "    return sparsity_matrix\n",
    "\n",
    "\n",
    "x1 = torch.Tensor([0,3,1,2])\n",
    "x2 = torch.Tensor([0,3,2,1])\n",
    "\n",
    "X = torch.rand(256,4096).to('cpu')\n",
    "# X = torch.Tensor([[0,3],[3,2],[1,0],[2,1]])\n",
    "A = torch.rand(64,256).to('cpu')\n",
    "A = A/torch.norm(A, dim=0, keepdim=True)\n",
    "Y = A @ X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = orthogonal_matching_pursuit_matrix(Y,A,sparsity=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = linear_model.orthogonal_mp(A.cpu().numpy(),Y.cpu().numpy(), n_nonzero_coefs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1024]), (256, 1024))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.shape, S2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 6.8686,\n",
       "         2.1188, 4.4725]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  6.86864614,  2.11873317,  4.47249603,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  3.46769309,  0.        ,  0.        ,  2.44842958,\n",
       "         5.37361908,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  7.39130545,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , 10.45657349,  0.        ,  0.        ,  3.45301104,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         6.29366493,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.40829277,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  3.96919799,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  4.09073067,  6.72810507,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         3.76558352,  0.        ,  5.29315805,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  4.20267963,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  5.19188261,  0.        ,\n",
       "         6.48649931,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.54743004,  0.        ,  0.        ,  0.49309978,  0.        ,\n",
       "         0.        ,  2.99140596, 11.50560856,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  6.7297411 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         5.74750471,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1[:20,0], S2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from skimage import io,data\n",
    "from src.model.spstfm.ksvd import KSVD\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "img=data.astronaut()\n",
    "rng_seed = 42\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "# io.imshow(img)\n",
    "\n",
    "# img_train = img[:256, :, :]\n",
    "# io.imshow(img_train)\n",
    "device = 'cuda'\n",
    "n_components = 256\n",
    "ksvd = KSVD(n_components=n_components,max_iter=100,tol=1e-6,sparsity=10).to(device)\n",
    "img = img.astype('float') / 255.0\n",
    "img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "img_norm = (img - torch.mean(img,dim=(-2,-1),keepdim=True)) / (torch.std(img,dim=(-2,-1),keepdim=True) + 1e-10)\n",
    "img_patch = torch.nn.Unfold(kernel_size=8, stride=8)(img_norm)\n",
    "img_patch = img_patch.reshape(3, 64, -1)\n",
    "dictionary_matrix = torch.zeros(3, 64, n_components,device=device)\n",
    "sparsity_matrix = torch.zeros(3, n_components, img_patch.shape[-1],device=device)\n",
    "for i in range(3):\n",
    "    img_patch_per_channel = img_patch[i]\n",
    "    dictionary_matrix_per_channel, sparsity_matrix_per_channel = ksvd.fit(img_patch_per_channel)\n",
    "    dictionary_matrix[i] = dictionary_matrix_per_channel\n",
    "    sparsity_matrix[i] = sparsity_matrix_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unfold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m a\u001b[39m.\u001b[39;49munfold(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unfold'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.random.rand(1,1,3,4)\n",
    "torch.nn.Unfold(kernel_size=2, stride=2)(torch.from_numpy(a)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
